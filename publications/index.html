<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>Publications and preprints</title><!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Publications and preprints" />
<meta name="author" content="Riccardo Graziosi" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="I’m a final-year PhD student at the Machine Learning Group within the Cambridge University Engineering Department. I’m broadly interested in scalable machine learning, including efficient transformer architectures, training data attribution, graphs, and robotics. I live in London, UK." />
<meta property="og:description" content="I’m a final-year PhD student at the Machine Learning Group within the Cambridge University Engineering Department. I’m broadly interested in scalable machine learning, including efficient transformer architectures, training data attribution, graphs, and robotics. I live in London, UK." />
<link rel="canonical" href="https://isaac-reid.github.io/publications/" />
<meta property="og:url" content="https://isaac-reid.github.io/publications/" />
<meta property="og:site_name" content="Isaac Reid" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-06-28T14:21:01+01:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Publications and preprints" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Riccardo Graziosi"},"dateModified":"2025-06-28T14:21:01+01:00","datePublished":"2025-06-28T14:21:01+01:00","description":"I’m a final-year PhD student at the Machine Learning Group within the Cambridge University Engineering Department. I’m broadly interested in scalable machine learning, including efficient transformer architectures, training data attribution, graphs, and robotics. I live in London, UK.","headline":"Publications and preprints","mainEntityOfPage":{"@type":"WebPage","@id":"https://isaac-reid.github.io/publications/"},"url":"https://isaac-reid.github.io/publications/"}</script>
<!-- End Jekyll SEO tag -->
<link type="application/atom+xml" rel="alternate" href="https://isaac-reid.github.io/feed.xml" title="Isaac Reid" /><link rel="shortcut icon" type="image/x-icon" href="/logo.png" />
  <link rel="stylesheet" href="/assets/css/main.css" />
</head><body a="light">
    <main class="page-content" aria-label="Content">
      <div class="w">
        <a href="/">..</a><article>
  <p class="post-meta">
    <time datetime="2025-06-28 14:21:01 +0100">2025-06-28</time>
  </p>
  
  <h1>Publications and preprints</h1>

  <style>
  body {
    background-color: #f8f5ee;
    margin: 0;
  }
  a {
    text-decoration: none;
    color: #008080;
  }

  a:hover {
    text-decoration: underline;
  }

</style>

<p><strong>Gemini Robotics 1.5: Pushing the Frontier of Generalist Robots with Advanced Embodied Reasoning, Thinking, and Motion Transfer</strong> <br />
<em>Published on GDM blog</em> <br />
GDM robotics team (very many authors) <br />
A new family of robotics foundation models, with improved reasoning and cross-embodiment transfer.
<a href="https://storage.googleapis.com/deepmind-media/gemini-robotics/Gemini-Robotics-1-5-Tech-Report.pdf">Paper</a></p>

<p><strong>Rotary Position Encodings for Graphs</strong><br />
<em>Preprint, under review</em>  <br />
<strong>Isaac Reid</strong>*, Arijit Sehanobish*, Cederik Höfs*, Bruno Mlodozeniec, Leonhard Vulpius, Federico Barbero, Adrian Weller, Krzysztof Choromanski, Richard E. Turner, Petar Veličković     <br />
You can extend rotary position encoings (RoPE) to graphs, and it automatically inherits a bunch of nice properties.<br />
<a href="https://arxiv.org/abs/2509.22259">Paper</a>  <br />
<em>* Denotes core contributors.</em></p>

<p><strong>Gaussian Random Features for Scalable Gaussian Processes</strong><br />
<em>ICLR 2026</em>  <br />
Matthew Zhang, Jihao Andreas Lin, Krzysztof Choromanski, Adrian Weller, Richard Turner, <strong>Isaac Reid</strong>    <br />
GRFs permit <em>very</em> efficient Bayesian optimisation on graphs, when you implement the sparse linear algebra properly and use iterative linear solvers instead of matrix inverses.  <br />
<a href="https://arxiv.org/abs/2509.03691">Paper</a></p>

<p><strong>Distributional Training Data Attribution</strong><br />
<em>NeurIPS 2025, accepted as spotlight paper</em>  <br />
Bruno Mlodozeniec<sup>†</sup>, <strong>Isaac Reid</strong><sup>†</sup>, Sam Power, David Krueger, Murat Erdogdu, Richard Turner, Roger Grosse    <br />
‘Influence’ of samples can be understood by how drastically the <em>distribution</em> over final trained models changes if they are removed. Influence functions emerge organically from this new mathematical formulation. <br />
<a href="https://arxiv.org/abs/2506.12965">Paper</a> <br />
<em><sup>†</sup> Denotes equal contribution. Order decided by who could swim the furthest underwater.</em></p>

<p><strong>Learning the RoPEs: Better 2D and 3D Position Encodings with STRING</strong><br />
<em>ICML 2025, accepted as spotlight paper</em>  <br />
Connor Schenck*, <strong>Isaac Reid</strong>*, Mithun George Jacob*, Alex Bewley*, Joshua Ainslie*, David
Rendleman*, Deepali Jain, Mohit Sharma, Avinava Dubey, Ayzaan Wahid, Sumeet Singh, René
Wagner, Tianli Ding, Chuyuan Fu, Arunkumar Byravan, Jake Varley, Alexey Gritsenko, Matthias
Minderer, Dmitry Kalashnikov, Jonathan Tompson, Vikas Sindhwani, Krzysztof Choromanski*  <br />
<strong>S</strong>eperable <strong>Tr</strong>anslationally <strong>In</strong>variant Position Encodin<strong>g</strong>s = STRING. A more general extension of Rotary Position Encodings (RoPE) using some very lightweight group theory.<br />
<a href="https://arxiv.org/pdf/2502.02562v1">Paper</a></p>

<p><strong>Linear Transformer Topological Masking with Graph Random Features</strong><br />
<em>ICLR 2025</em><br />
<strong>Isaac Reid</strong>, Kumar Avinava Dubey, Deepali Jain, Will Whitney, Amr Ahmed, Joshua Ainslie, Alex Bewley, Mithun Jacob, Aranyak Mehta, David Rendleman, Connor Schenck, Richard E. Turner, René Wagner, Adrian Weller, Krzysztof Choromanski<br />
How can you efficiently incorporate information about the underlying graph structure into a linear attention transformer, where the attention matrix is never explicitly instantiated in memory? Using GRFs, of course.  <br />
<a href="https://arxiv.org/abs/2410.03462">Paper</a></p>

<p><strong>Optimal Time Complexity Algorithms for Computing General Random Walk Graph Kernels on Sparse Graphs</strong><br />
<em>AISTATS 2025</em><br />
Krzysztof Choromanski*, <strong>Isaac Reid</strong>*, Arijit Sehanobish, Avinava Dubey<br />
By simulating correlated random walks on an ensemble of graphs, you can estimate the graph kernel between any given pair in linear time.    <br />
<a href="https://arxiv.org/abs/2410.10368">Paper</a></p>

<p><strong>Variance-Reducing Couplings for Random Features: Perspectives from Optimal Transport</strong><br />
<em>ICLR 2025</em><br />
<strong>Isaac Reid</strong>, Stratis Markou, Krzysztof Choromanski, Richard E. Turner, Adrian Weller<br />
Variance reduction in Monte Carlo is really a multi-marginal optimal transport problem, and treating it as such gives us tools to sample more efficiently in Euclidean and discrete space.  <br />
<a href="https://arxiv.org/abs/2405.16541">Paper</a> <a href="https://github.com/cambridge-mlg/learnable-qmc">Code</a></p>

<p><del>Universal</del> <strong>General Graph Random Features</strong><br />
<em>ICLR 2024</em>        <br />
<strong>Isaac Reid</strong>*, Krzysztof Choromanski*, Eli Berger*, Adrian Weller    <br />
You give me an arbitrary function of a weighted adjacency matrix, I give you a random feature mechanism to approximate it efficiently (name changed during review).   <br />
<a href="https://arxiv.org/abs/2310.04859">Paper</a> <a href="https://github.com/isaac-reid/general_graph_random_features">Code</a></p>

<p><strong>Repelling Random Walks</strong>    <br />
<em>ICLR 2024</em>     <br />
<strong>Isaac Reid</strong>, Eli Berger, Krzysztof Choromanski, Adrian Weller      <br />
The QMC scheme below wasn’t so good after all; now we correlate walker <em>directions</em> in an algorithm of broader interest.     <br />
<a href="https://arxiv.org/abs/2310.04854">Paper</a> <a href="https://github.com/isaac-reid/repelling_random_walks">Code</a></p>

<p><strong>Quasi-Monte Carlo Graph Random Features</strong> <br />
<em>NeurIPS 2023, accepted as spotlight paper</em> <br />
<strong>Isaac Reid</strong>, Krzysztof Choromanski, Adrian Weller    <br />
A QMC scheme that induces correlations between the lengths random walks
on a graph. <br />
<a href="https://arxiv.org/abs/2305.12470">Paper</a> <a href="https://github.com/isaac-reid/antithetic_termination">Code</a></p>

<p><strong>Simplex Random Features</strong> <br />
<em>ICML 2023, accepted with oral presentation</em> <br />
<strong>Isaac Reid</strong>, Krzysztof Choromanski, Valerii Likhosherstov, Adrian Weller <br />
Derivation of an optimal random feature mechanism for unbiased approximation of the Gaussian
kernel, motivated by new analytical results and tested with Transformers.   <br />
<a href="https://arXiv.org/abs/2301.13856">Paper</a> <a href="https://github.com/isaac-reid/simplex_random_features">Code</a></p>

<p><strong>Entanglement Barriers in Dual-Unitary Circuits</strong>     <br />
<em>Phys. Rev. B 104, 014301 – Published 1 July 2021</em>     <br />
<strong>Isaac Reid</strong>, Bruno Bertini   <br />
Exact characterisation of the dynamics of quantum entanglement arising after a quantum quench in a
many-body, locally interacting system, including both the integrable and completely chaotic regimes.   <br />
<a href="https://arxiv.org/abs/2103.12794">Paper</a></p>

</article>
      </div>
    </main>
  </body>
</html>